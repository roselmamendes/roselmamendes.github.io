---
layout: post
title:  "Estamos construindo tecnologias racistas?"
modified:   2017-04-08
categories: tec
tags: [bias algorithm, racismo, IA, programação]
image:
  feature: /racismo-tecnologia/start-trek-old-version.jpg
  credit: Uhura - Star Trek
  creditlink: https://pt.wikipedia.org/wiki/Uhura
excerpt: "Enquanto tecnologistas qual nossa parcela de contribuição quanto as injustiças sociais? Eu e tantas Mulheres Negras sabemos qual o papel que uma tecnologia racista tem em nossas vidas."
comments: true
share: true
hidelogo: true
published: true
---

Enquanto tecnologistas qual nossa parcela de contribuição quanto as injustiças sociais?

Minha resposta é: uma boa parte de contribuição.

Quando não nos perguntamos as bases da construção de qualquer tecnologia, nós podemos perpetuar injustiças.

A computação no final das contas é "segui as instruções de um ser humano", repetidamente. A computação trouxe facilidades nas nossas decisões diárias, mas como isso é construído?

"Eu só programo meu Rails/Django/React/etc, o que é que eu tenho a ver?"

#### O que é que temos a ver

Quando se é uma Mulher Negra tecnologista, você sabe que ser da área de Tecnologia/Computação não é só uma profissão, é um ato político também.

Ser Mulher Negra, se dizer ser Mulher Negra, viver a negritude, trabalhar, predominar em uma profissão - <b>ainda dominada pela branquitude</b> - é um ato político, [porque estou aonde não deveria está de acordo com a lógica social que vivemos](https://super.abril.com.br/videos/2-minutos-para-entender/2-minutos-para-entender-desigualdade-racial-no-brasil/).

Há uma frase da [Angela Davis](https://www.cartacapital.com.br/sociedade/angela-davis-e-o-significado-da-emancipacao-da-mulher-negra) sobre o movimento das Mulheres Negras:

["Quando a mulher negra se movimenta, toda a estrutura da sociedade se movimenta com ela"](https://brasil.elpais.com/brasil/2017/07/27/politica/1501114503_610956.html)

Eu e tantas outras Mulheres Negras sabemos o papel que uma tecnologia racista tem em nossas vidas.

<figure>
	<a href="https://youtu.be/_dg86g-QlM0"><img src="/images/racismo-tecnologia/franchesca ramsey equality.gif" alt="image"></a>
	<figcaption>https://youtu.be/_dg86g-QlM0 tem como colocar a legenda em portugues</figcaption>
</figure>

<br>
<b>Aliado/Aliada são verbos.</b> 

Link pro vídeo da Franchesca (a que está no gif acima) ao lado ->

A luta das Mulheres Negras é por dar acesso a esse grupo os mesmos direitos que pessoas brancas possuem, e não tirar direitos de alguém. Quando você branco luta - também, ao lado - contra o racismo, você está lutando por um mundo melhor para você e todas as pessoas a seu redor. <b>Ninguém perde quando se dá voz a quem não tinha direito a ter voz.</b> 

Isso é justiça na vida real <b>e no campo da Computação também</b>.

#### Tecnologia pode ser racista?

Ovetta Sampson nos questiona com seu [texto](https://www.linkedin.com/pulse/can-technology-racist-ovetta-sampson?articleId=6166609662327152640#comments-6166609662327152640&trk=prof-post). Ela relata a conversa que teve com uma pessoa sobre isso, e já começa o texto falando do vídeo de um rapaz que tenta utlizar um dispenser de sabão:

<iframe width="560" height="315" src="https://www.youtube.com/embed/1lgDiAInFLY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<br>
Agora vamos a um [relatório](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) da Propublica sobre o sistema Compas. 

O Compas é um algortimo que se propoe a calcular a reincidencia de uma pessoa réu em julgamento nos Estados Unidos. A partir de uma investigação da Propublica: ["[...]Os dados mostraram que os acusados ​​negros tinham duas vezes mais chances de serem erroneamente rotulados como de maior risco do que os réus brancos.[...]"](https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say) no sistema.

A empresa do algoritmo se negou a divulgar como o algoritmo tomava a decisão, mas fica evidente que o "código neutro" do programa não levou em consideração todo o historico opressor a que pessoas negras são expostas em suas vidas. O algoritmo ainda não consegue processar as complexidades das nossas relações sociais. Ou pelo menos nós seres humanos ainda não conseguimos "programar" as máquinas para tal.

E ...

[Em 2015, a ferramenta Photos do Google colocou a legenda de um album de fotos como Gorilas. O album tinha fotos de pessoas negras.](https://mashable.com/2015/07/01/google-photos-black-people-gorillas/#oaCoVg0AJuq7).

[Algoritmos que classificam nomes afro-descendentes como não "agradaveis".](https://www.theguardian.com/technology/2017/apr/13/ai-programs-exhibit-racist-and-sexist-biases-research-reveals)

[Em 2009, a HP lançou computadores com webcams que acompanhavam a pessoa ao passo que ela se movia, mas isso não funcionava com pessoas negras](https://www.youtube.com/watch?v=t4DT3tQqgRM)

[A tecnologia não é racista, mas ela aprende de nós como ser.](https://www.tecmundo.com.br/inteligencia-artificial/102782-tay-twitter-conseguiu-corromper-ia-microsoft-24-horas.htm)

#### A <strike>coisa</strike> tecnologia tá preta

Existem muitas iniciativas voltadas pra discuti sobre o viés algortimico. Alguma delas:

[MathWashing](https://www.mathwashing.com/)(vou traduzi livremente para <i>Cegueira Matemática</i>): algoritmos não são neutros, pense criticamente, exija transparência.

[Algorithm Justice League](https://www.ajlunited.org/)(Liga da Justiça Algoritmica): discuti os algoritmos que podem ser discriminatórios e como podemos preveni a construção deles.

[Data for Black Lives](https://medium.com/@YESHICAN/an-open-letter-to-facebook-from-the-data-for-black-lives-movement-81e693c6b46c)(Dados por vidas Negras): usando dados pelas pessoas negras.

Quando falamos de não construi tecnologias racistas, isso significa também equipes racialmente diversas, onde pessoas negras possam ter suas vozes escutadas. Pois somos, contra tudo e todos, programadoras, cientistas, engenheiras, analistas, e tudo o mais.

<figure>
	<a href="http://www.startrek.com/database_article/burnham"><img src="/images/racismo-tecnologia/burnham-tardigrade-scans.jpg" alt="image"></a>
	<figcaption>Michael Burnham - Star Trek</figcaption>
</figure>


#### Links

[Sobre estudo da Propublica e o software Compas](https://apublica.org/2016/06/software-que-avalia-reus-americanos-cria-injusticas-na-vida-real/)

[How white engineers built racist code – and why it's dangerous for black people](https://www.theguardian.com/technology/2017/dec/04/racist-facial-recognition-white-coders-black-people-police)
